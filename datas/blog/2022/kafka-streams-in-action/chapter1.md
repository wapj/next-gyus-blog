---
title: "1장 카프카 스트림즈에 오신 것을 환영합니다."
date: "2022-05-02"
tags: ["kafka", "kafka streams"]
category: dev
featured: "/images/2022/0502/kafkastreams.jpeg"
published: true
---

## 간단하게 살펴보는 빅 데이터 처리의 역사

**개요**

- 프로그래밍 환경과 프레임워크 기술은 폭발적으로 계속 변하고 있음.
- 그중에 한가지 변하지 않는 것 매일 점점 더 많은 데이터를 처리해야 한다.
- 대량의 데이터를 벌크 처리하는 것만으로는 충분하지 않음
- 데이터를 실시간(스트림처리)으로 처리 해야할 필요성 증가 → 카프카 스트림즈

## 빅 데이터의 근원
- 구글이 시작된 1998년에 빅 데이터 시대가 시작 됐다고 할 수 있음
- 구글은 페이지랭크 알고리즘을 사용해서 웹사이트의 순위를 매김

### 맵리듀스의 중요개념
- 맵과 리듀스 함수가 새로운 개념은 아님. 이런 간단한 개념을 많은 장비에 대규모로 적용한 것이 독창적인 것임
- 맵리듀스의 핵심은 함수형 프로그래밍
- 맵리듀스의 패러다임이 도입한 핵심개념중 일부가 카프카 스트림즈에도 자리잡음
  - 대규모 처리를 위해 클러스터에 데이터를 분산하는 방법
  - 한대의 장비에서 5TB를 작업하기는 힘들지만 천대의 장비에서 1GB씩 처리하는 것은 할만하다.
  - 분산 데이터를 함께 그룹짓기 위한 키/값 쌍과 파티션 사용
    - 파티션은 key.hashCode() % 파티션 갯수로 구한다.
  - 실패를 피하는 대신 복제를 사용해 실패를 수용
    - 구글 맵리듀스의 또 다른 구성요소는 GFS이다. 하둡은 HDFS라는 오픈소스 구현체를 만들었다. GFS와 HDFS은 모두 데이터를 블록으로 분할하고 이런 브록을 클러스터에 분산한다. 클러스터 전체에 블록을 복제해서 오류를 수용한다. 기본적으로 3개의 복제본을유지

### 배치처리로는 충분하지 않다.
- 하둡은 맵리듀스를 사용해서 배치처리를 한다.
- 그러나 좀더 신속하게 반응해야하는 요구사항이 생겼다.

## 스트림 처리 소개
스트림 처리란?  
- 데이터가 시스템에 도착하는 대로 처리하는 것.
- 데이터를 수집 저장 하는 것이 아니라 무한한 데이터 스트림을 유입되는 대로 연속으로 계산해서 처리할 수 있는 능력


스트림 처리를 사용하면 좋은 경우 : 데이터가 도착하자 마자 빠르게 즉시 보고 혹은 조치를 취해야 하는 경우

- 신용카드 사기
- 침입탐지
- 대규모 경주
- 금융업계

사용하지 말이야할 경우 : 심층 분석 및 분석을 위한 대형 데이터 저장소에 저장이 필요한 경우

- 경제 예측
- 학교 교과 과정 변경

## 구매 거래 처리
지마트(가상의 서비스) 스트리밍 데이터 팀의 개발자가 되어서 데이터 처리를 해보자.

### 요구사항

- 프라이버시 : 고객의 신용카드 정보 마스킹
- 고객보상 : 구매 후 즉시 보너스 포인트 지급
- 판매 데이터 : 할인가 및 특가제공
- 구매 데이터는 이력 및 분석을 위해 스토리지 저장

![1](/images/2022/0502/ksia01.png)

## 구매 트랜잭션에 대한 관점 변경
- 구매 : 원본 소스
- 구매 → 마스킹 : 신용카드 마스킹 작업. 마스킹을 기반으로 다른 작업 진행
- 마스킹 → 패턴 : 전국 어디에서 제품을 구매하는지 알아내기 위해 관련 정보를 추출
- 마스킹 → 리워드 : 구매후 포인트를 제공
- 마스킹 → 스토리지 : 추가 분석을 위해 구매데이터를 NoSQL데이터 저장소에 기록

## 처리노드로서의 그래프 카프카 스트림즈
- 카프카 스트림즈는 이벤트별로 레코드를 처리 할 수 있는 라이브러리이다.
- 각 레코드를 가능한 빨리 처리한다.
- 카프카 스트림즈에서는 처리 노드(프로세서)의 토폴로지를 정의한다.
- DAG를 깊이우선방식으로 진행함 : 백프레셔 내장 필요없음
